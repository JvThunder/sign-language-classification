{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jvthunder/sign-language-classification?scriptVersionId=121233415\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Introduction\n\nThis notebook is created for [Kaggle's Sign Langueage Classifier Competition].(https://www.kaggle.com/competitions/asl-signs/code)\n\nIn this notebook, I used notebooks from various sources and modify them to get this notebook. All credits are due to the authors of these notebooks and please give upvotes to them if you also find it useful.\n\n- I used some of the data visualization of the landmark from [Sign Language EDA & Visualization] (https://www.kaggle.com/code/mayukh18/sign-language-eda-visualization).\n\n- I used the preprocessed tensorflow Dataset from [tfdataset-of-google-isl-recognition-data] (https://www.kaggle.com/datasets/aapokossi/saved-tfdataset-of-google-isl-recognition-data)\n\n- I train my model following the notebook. [Submission for variable length time-series model] (https://www.kaggle.com/code/aapokossi/submission-for-variable-length-time-series-model) I then tweak the layers and the epoch to increase the accuracy.\n\nIn future versions, I might improve on the model and give more comments to help people start on this competition. ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"contents\"></a>\n# Contents\n1. [Import Libraries and Set File Directories](#section-one)\n2. [Visualize data](#section-two)\n3. [Load Data](#section-three)\n4. [Train Model](#section-four)\n5. [Submit Model](#section-five)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# Import Libraries and Set File Directories","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers, optimizers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-05T14:59:21.726723Z","iopub.execute_input":"2023-03-05T14:59:21.72755Z","iopub.status.idle":"2023-03-05T14:59:21.752322Z","shell.execute_reply.started":"2023-03-05T14:59:21.727519Z","shell.execute_reply":"2023-03-05T14:59:21.75115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LANDMARK_FILES_DIR = \"/kaggle/input/asl-signs/train_landmark_files\"\nTRAIN_FILE = \"/kaggle/input/asl-signs/train.csv\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n# Visualize data","metadata":{}},{"cell_type":"code","source":"sample = pd.read_parquet(\"/kaggle/input/asl-signs/train_landmark_files/16069/100015657.parquet\")\nsample.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-05T14:59:21.754112Z","iopub.execute_input":"2023-03-05T14:59:21.75506Z","iopub.status.idle":"2023-03-05T14:59:21.877337Z","shell.execute_reply.started":"2023-03-05T14:59:21.755024Z","shell.execute_reply":"2023-03-05T14:59:21.876426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_left_hand = sample[sample.type == \"left_hand\"]\nsample_right_hand = sample[sample.type == \"right_hand\"]\nedges = [(0,1),(1,2),(2,3),(3,4),(0,5),(0,17),(5,6),(6,7),(7,8),(5,9),(9,10),(10,11),(11,12),\n         (9,13),(13,14),(14,15),(15,16),(13,17),(17,18),(18,19),(19,20)]\n\ndef plot_frame(df, frame_id, ax):\n    df = df[df.frame == frame_id].sort_values(['landmark_index'])\n    x = list(df.x)\n    y = list(df.y)\n    \n    ax.scatter(df.x, df.y, color='dodgerblue')\n    for i in range(len(x)):\n        ax.text(x[i], y[i], str(i))\n        \n    for edge in edges:\n        ax.plot([x[edge[0]], x[edge[1]]], [y[edge[0]], y[edge[1]]], color='salmon')\n        ax.set_xlabel(f\"Frame no. {frame_id}\")\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n\n    \ndef plot_frame_seq(df, frame_range, n_frames):\n    frames = np.linspace(frame_range[0],frame_range[1],n_frames, dtype = int, endpoint=True)\n    fig, ax = plt.subplots(n_frames, 1, figsize=(5,25))\n    for i in range(n_frames):\n        plot_frame(df, frames[i], ax[i])\n        \n    plt.show()\n\n    \nplot_frame_seq(sample_left_hand, (178,186), 5)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T14:59:21.878903Z","iopub.execute_input":"2023-03-05T14:59:21.879246Z","iopub.status.idle":"2023-03-05T14:59:22.898757Z","shell.execute_reply.started":"2023-03-05T14:59:21.879212Z","shell.execute_reply":"2023-03-05T14:59:22.897681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n# Load Data","metadata":{}},{"cell_type":"code","source":"# Set constants and pick important landmarks\nLANDMARK_IDX = [0,9,11,13,14,17,117,118,119,199,346,347,348] + list(range(468,543))\nDATA_PATH = \"/kaggle/input/saved-tfdataset-of-google-isl-recognition-data/GoogleISLDatasetBatched\"\nDS_CARDINALITY = 185\nVAL_SIZE  = 20\nN_SIGNS = 250\nROWS_PER_FRAME = 543","metadata":{"execution":{"iopub.status.busy":"2023-03-05T14:59:22.901302Z","iopub.execute_input":"2023-03-05T14:59:22.902792Z","iopub.status.idle":"2023-03-05T14:59:22.914372Z","shell.execute_reply.started":"2023-03-05T14:59:22.90275Z","shell.execute_reply":"2023-03-05T14:59:22.913234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(ragged_batch, labels):\n    ragged_batch = tf.gather(ragged_batch, LANDMARK_IDX, axis=2)\n    ragged_batch = tf.where(tf.math.is_nan(ragged_batch), tf.zeros_like(ragged_batch), ragged_batch)\n    return tf.concat([ragged_batch[...,i] for i in range(3)],-1), labels\n\ndataset = tf.data.Dataset.load(DATA_PATH)\ndataset = dataset.map(preprocess)\nval_ds = dataset.take(VAL_SIZE).cache().prefetch(tf.data.AUTOTUNE)\ntrain_ds = dataset.skip(VAL_SIZE).cache().shuffle(20).prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T14:59:22.916002Z","iopub.execute_input":"2023-03-05T14:59:22.917122Z","iopub.status.idle":"2023-03-05T14:59:34.189463Z","shell.execute_reply.started":"2023-03-05T14:59:22.917085Z","shell.execute_reply":"2023-03-05T14:59:34.188315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-four\"></a>\n# Train Model","metadata":{}},{"cell_type":"code","source":"def get_callbacks():\n    return [\n            tf.keras.callbacks.EarlyStopping(\n            monitor=\"val_accuracy\",\n            patience=10,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor = \"val_accuracy\",\n            factor = 0.5,\n            patience = 3\n        ),\n    ]\n\ndef dense_block(units, name):\n    fc = layers.Dense(units)\n    norm = layers.LayerNormalization()\n    act = layers.Activation(\"relu\")\n    return lambda x: act(norm(fc(x)))\n\ndef classifier(lstm_units):\n    lstm = layers.LSTM(lstm_units)\n    out = layers.Dense(N_SIGNS, activation=\"softmax\")\n    return lambda x: out(lstm(x))","metadata":{"execution":{"iopub.status.busy":"2023-03-05T14:59:34.191322Z","iopub.execute_input":"2023-03-05T14:59:34.19175Z","iopub.status.idle":"2023-03-05T14:59:34.20207Z","shell.execute_reply.started":"2023-03-05T14:59:34.191693Z","shell.execute_reply":"2023-03-05T14:59:34.200805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_units = [512, 256]\nlstm_units = 256\n\n#define the inputs (ragged batches of time series of landmark coordinates)\ninputs = tf.keras.Input(shape=(None,3*len(LANDMARK_IDX)), ragged=True)\n\n# dense encoder model\nx = inputs\nfor i, n in enumerate(encoder_units):\n    x = dense_block(n, f\"encoder_{i}\")(x)\n\n# classifier model\nout = classifier(lstm_units)(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=out)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-05T15:11:48.222116Z","iopub.execute_input":"2023-03-05T15:11:48.2225Z","iopub.status.idle":"2023-03-05T15:11:48.719467Z","shell.execute_reply.started":"2023-03-05T15:11:48.222468Z","shell.execute_reply":"2023-03-05T15:11:48.718667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = DS_CARDINALITY - VAL_SIZE\nboundaries = [steps_per_epoch * n for n in [30,50,70]]\nvalues = [1e-3,1e-4,1e-5,1e-6]\nlr_sched = optimizers.schedules.PiecewiseConstantDecay(boundaries, values)\noptimizer = optimizers.Adam(lr_sched)\n\nmodel.compile(optimizer=optimizer,\n              loss=\"sparse_categorical_crossentropy\",\n              metrics=[\"accuracy\",\"sparse_top_k_categorical_accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-05T15:11:50.590993Z","iopub.execute_input":"2023-03-05T15:11:50.591968Z","iopub.status.idle":"2023-03-05T15:11:50.609668Z","shell.execute_reply.started":"2023-03-05T15:11:50.591931Z","shell.execute_reply":"2023-03-05T15:11:50.608534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_ds,\n          validation_data = val_ds,\n          callbacks = get_callbacks(),\n          epochs = 100)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T15:11:51.187832Z","iopub.execute_input":"2023-03-05T15:11:51.188726Z","iopub.status.idle":"2023-03-05T15:12:35.838805Z","shell.execute_reply.started":"2023-03-05T15:11:51.188677Z","shell.execute_reply":"2023-03-05T15:12:35.837687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-five\"></a>\n# Submit Model","metadata":{}},{"cell_type":"code","source":"model.summary(expand_nested=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_inference_model(model):\n    inputs = tf.keras.Input(shape=(ROWS_PER_FRAME,3), name=\"inputs\")\n    \n    # drop most of the face mesh\n    x = tf.gather(inputs, LANDMARK_IDX, axis=1)\n\n    # fill nan\n    x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n\n    # flatten landmark xyz coordinates ()\n    x = tf.concat([x[...,i] for i in range(3)], -1)\n\n    x = tf.expand_dims(x,0)\n    \n    # call trained model\n    out = model(x)\n    \n    # explicitly name the final (identity) layer for the submission format\n    out = layers.Activation(\"linear\", name=\"outputs\")(out)\n    \n    inference_model = tf.keras.Model(inputs=inputs, outputs=out)\n    inference_model.compile(loss=\"sparse_categorical_crossentropy\",\n                            metrics=\"accuracy\")\n    return inference_model","metadata":{"execution":{"iopub.status.busy":"2023-03-05T15:12:35.840926Z","iopub.execute_input":"2023-03-05T15:12:35.841693Z","iopub.status.idle":"2023-03-05T15:12:35.850055Z","shell.execute_reply.started":"2023-03-05T15:12:35.841653Z","shell.execute_reply":"2023-03-05T15:12:35.848757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inference_model = get_inference_model(model)\ninference_model.summary(expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T15:12:35.851784Z","iopub.execute_input":"2023-03-05T15:12:35.85252Z","iopub.status.idle":"2023-03-05T15:12:36.287042Z","shell.execute_reply.started":"2023-03-05T15:12:35.85248Z","shell.execute_reply":"2023-03-05T15:12:36.286262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_keras_model(inference_model)\ntflite_model = converter.convert()\nmodel_path = \"model.tflite\"\n\nwith open(model_path, 'wb') as f:\n    f.write(tflite_model)\n!zip submission.zip $model_path","metadata":{"execution":{"iopub.status.busy":"2023-03-05T15:12:36.28893Z","iopub.execute_input":"2023-03-05T15:12:36.289605Z","iopub.status.idle":"2023-03-05T15:12:44.103271Z","shell.execute_reply.started":"2023-03-05T15:12:36.289565Z","shell.execute_reply":"2023-03-05T15:12:44.101673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}